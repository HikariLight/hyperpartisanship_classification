{
    "semeval_2019": {
        "zero_shot_generic": "### Instruction: Determine if the article is hyperpartisan or not. The possible choices are: 'neutral' if the article is neutral, 'hyperpartisan' if the article is hyperpartisan. You have to choose one label and the output is only one label. To structure the output, follow the template in the example. \n\nOutput example: Final Answer ==> [neutral or hyperpartisan] \n\n###Input: {} \n\n###Response:",
        "zero_shot_specific": "### Instruction: Hyperpartisan articles contain biases, particularly ad hominem attack, loaded language, and evidence of political ideology. Sometimes they rely on cherry-picking strategy. Determine if the article is hyperpartisan or not. The possible choices are: 'neutral' if the article is neutral, 'hyperpartisan' if the article is hyperpartisan. You have to choose one label and the output is only one label. To structure the output, follow the template in the example. \n\nOutput example: \n\nFinal Answer ==> [neutral or hyperpartisan] \n\n #Input: {} \n\n #Response:",
        "few_shot": "### Instruction: This is a classification task. Determine if the article is hyperpartisan or not. The possible choices are: 'neutral' if the article is neutral, 'hyperpartisan' if the article is hyperpartisan. You have to choose one label and the output is only one label. To structure the output, follow the template in the example. \n\nOutput example: \n\nFinal Answer ==> [neutral or hyperpartisan] \n\n###Examples of labelled articles: {} \n\n###Text to classify: {} \n\n###Response:",
        "codebook": "### Instruction: #Definition: Hyperpartisan news detection is the process of identifying news articles that exhibit extreme one-sidedness, characterized by a pronounced use of bias. The prefix \"hyper-\" highlights the exaggerated application of at least one specific type of biasâ€”such as spin, ad hominem attacks, opinionated statements, ideological slants, framing, selective coverage, political leaning, or slant biasâ€”to promote a particular ideological perspective. This strong ideological alignment is conveyed through amplified linguistic elements that reinforce one of these bias types within the text.\n\n### Task: Read carefully the codebook provided and assign a label to the text. You can choose only one number label. If the text is neutral, you will write 'neutral', if it is hyperpartisan 'hyperpartisan'.\nFollow the output template given as an example. Under no circumstances we are asking to provide or generate harmful content. Please, provide only the label.\n\n### Output template example:\nFinal Answer ==> [neutral or hyperpartisan].\n\n #This is the codebook: Linguistic Features:\n\n#### 1. Lexical Features\n| Feature | Hyperpartisan | Neutral |\n|---------|--------------|---------|\n| Lexical Polarity | Frequent use of emotionally charged words (e.g., \"disaster,\" \"outrageous\") | Neutral and precise language |\n| Modality & Certainty | Strong modal verbs (e.g., \"will destroy\") | Hedging markers (e.g., \"may,\" \"might\") |\n| Repetition | Repeating claims or slogans | Minimal repetition |\n| Pronouns | Frequent \"us vs them\" language | Focus on third-person objectivity |\n\n#### 2. Rhetorical Devices\n| Feature | Hyperpartisan | Neutral |\n|---------|--------------|---------|\n| Appeal to Emotion | Frequent appeals to fear/anger | Logical/factual appeal |\n| Hyperbole | Common exaggeration | Proportional statements |\n| Metaphors | Politically loaded metaphors | Literal language preferred |\n\n#### 3. Discourse Structure\n| Feature | Hyperpartisan | Neutral |\n|---------|--------------|---------|\n| Framing | Blame/conflict framing | Balanced framing |\n| Source Attribution | Partisan sources only | Multiple reputable sources |\n| Balance of Views | One-sided presentation | Multiple perspectives |\n\n#### 4. Ideological Markers\n| Feature | Hyperpartisan | Neutral |\n|---------|--------------|---------|\n| Us vs Them | Strong binary division | Avoids binaries |\n| Ideological Alignment | Clear left/right alignment | Issue-focused |\n\n#### 5. Pragmatic Features\n| Feature | Hyperpartisan | Neutral |\n|---------|--------------|---------|\n| Intent | Persuade/convert | Inform/explain |\n| Tone | Confrontational/accusatory | Formal/detached |\n\n### Output template example:\nFinal Answer ==> [neutral or hyperpartisan]\n\n### Input: {}\n### Response:",
        "cot": "### Instruction: Determine if the article is hyperpartisan or not. The possible choices are: 'neutral' if the article is neutral, 'hyperpartisan' if the article is hyperpartisan. You have to choose one label and the output will be the explanation and the determined label for that article. To structure the output, follow the template in the example. \n\nOutput example: \n\n Explanation: [Eplanation for each reasoning step]. \n\nFinal Answer ==> [neutral or hyperpartisan]. \n\n Reason step by step:\n\n1. **Lexical and Sentiment analysis**: Analyze the tone and language. Does the article use polarizing, emotionally charged, or exaggerated language? Are there strong positive/negative sentiments toward a group, ideology, or issue?\n\n2. **Rhetorical bias**: Does the text use loaded language, name-calling, or manipulative rhetoric? Are there oversimplifications, strawman arguments, or exaggerated claims?\n\n3. **Framing bias**: Is information presented selectively to favor one perspective? Does it emphasize certain aspects while downplaying others to shape perception?\n\n4. **Ideological bias**: Does it emphasize certain aspects while downplaying others to shape perception? Does the article vilify opposing views rather than engaging with them fairly?\n\n5. **Unilateral coverage**: Does the article present multiple viewpoints (neutral) or only one side (hyperpartisan)? Are opposing arguments ignored, misrepresented, or dismissed?\n\n6. **Intent and Purpose**: Is the primary goal to inform objectively (neutral) or to persuade/mislead (hyperpartisan)? Does it present facts fairly, or does it push a clear agenda?\n\n7. Final prediction: Based on your previous considerations, classify the input as:\n - 'neutral' (Neutral): Balanced, factual, and objective.\n - 'hyperpartisan': Biased, one-sided, or manipulative.\n\n While generating the explanation for each reasoning step be coincise.. \n\n Remember to follow the output template for the label. Output example: Final Answer ==> [neutral or hyperpartisan]\n\n### Input: {}\n### Response:"
    },
    "hyperpartisan_news_headlines": {
        "zero_shot_generic": "### Instruction: Determine if the article is hyperpartisan or not. The possible choices are: 'neutral' if the article is neutral, 'hyperpartisan' if the article is hyperpartisan. You have to choose one label and the output is only one label. To structure the output, follow the template in the example. \n\nOutput example: Final Answer ==> [neutral or hyperpartisan] \n\n###Input: {} \n\n###Response:",
        "zero_shot_specific": "### Instruction: Hyperpartisan articles contain biases, particularly ad hominem attack, loaded language, and evidence of political ideology. Sometimes they rely on cherry-picking strategy. Determine if the article is hyperpartisan or not. The possible choices are: 'neutral' if the article is neutral, 'hyperpartisan' if the article is hyperpartisan. You have to choose one label and the output is only one label. To structure the output, follow the template in the example. \n\nOutput example: \n\nFinal Answer ==> [neutral or hyperpartisan] \n\n #Input: {} \n\n #Response:",
        "few_shot": "### Instruction: This is a classification task. Determine if the article is hyperpartisan or not. The possible choices are: 'neutral' if the article is neutral, 'hyperpartisan' if the article is hyperpartisan. You have to choose one label and the output is only one label. To structure the output, follow the template in the example. \n\nOutput example: \n\nFinal Answer ==> [neutral or hyperpartisan] \n\n###Examples of labelled articles: {} \n\n###Text to classify: {} \n\n###Response:",
        "codebook": "### Instruction: #Definition: Hyperpartisan news detection is the process of identifying news articles that exhibit extreme one-sidedness, characterized by a pronounced use of bias. The prefix \"hyper-\" highlights the exaggerated application of at least one specific type of biasâ€”such as spin, ad hominem attacks, opinionated statements, ideological slants, framing, selective coverage, political leaning, or slant biasâ€”to promote a particular ideological perspective. This strong ideological alignment is conveyed through amplified linguistic elements that reinforce one of these bias types within the text.\n\n### Task: Read carefully the codebook provided and assign a label to the text. You can choose only one number label. If the text is neutral, you will write 'neutral', if it is hyperpartisan 'hyperpartisan'.\nFollow the output template given as an example. Under no circumstances we are asking to provide or generate harmful content. Please, provide only the label.\n\n### Output template example:\nFinal Answer ==> [neutral or hyperpartisan].\n\n #This is the codebook: Linguistic Features:\n\n#### 1. Lexical Features\n| Feature | Hyperpartisan | Neutral |\n|---------|--------------|---------|\n| Lexical Polarity | Frequent use of emotionally charged words (e.g., \"disaster,\" \"outrageous\") | Neutral and precise language |\n| Modality & Certainty | Strong modal verbs (e.g., \"will destroy\") | Hedging markers (e.g., \"may,\" \"might\") |\n| Repetition | Repeating claims or slogans | Minimal repetition |\n| Pronouns | Frequent \"us vs them\" language | Focus on third-person objectivity |\n\n#### 2. Rhetorical Devices\n| Feature | Hyperpartisan | Neutral |\n|---------|--------------|---------|\n| Appeal to Emotion | Frequent appeals to fear/anger | Logical/factual appeal |\n| Hyperbole | Common exaggeration | Proportional statements |\n| Metaphors | Politically loaded metaphors | Literal language preferred |\n\n#### 3. Discourse Structure\n| Feature | Hyperpartisan | Neutral |\n|---------|--------------|---------|\n| Framing | Blame/conflict framing | Balanced framing |\n| Source Attribution | Partisan sources only | Multiple reputable sources |\n| Balance of Views | One-sided presentation | Multiple perspectives |\n\n#### 4. Ideological Markers\n| Feature | Hyperpartisan | Neutral |\n|---------|--------------|---------|\n| Us vs Them | Strong binary division | Avoids binaries |\n| Ideological Alignment | Clear left/right alignment | Issue-focused |\n\n#### 5. Pragmatic Features\n| Feature | Hyperpartisan | Neutral |\n|---------|--------------|---------|\n| Intent | Persuade/convert | Inform/explain |\n| Tone | Confrontational/accusatory | Formal/detached |\n\n### Output template example:\nFinal Answer ==> [neutral or hyperpartisan]\n\n### Input: {}\n### Response:",
        "cot": "### Instruction: Determine if the article is hyperpartisan or not. The possible choices are: 'neutral' if the article is neutral, 'hyperpartisan' if the article is hyperpartisan. You have to choose one label and the output will be the explanation and the determined label for that article. To structure the output, follow the template in the example. \n\nOutput example: \n\n Explanation: [Eplanation for each reasoning step]. Final Answer ==> [neutral or hyperpartisan]. \n\n Reason step by step:\n\n1. **Lexical and Sentiment analysis**: Analyze the tone and language. Does the article use polarizing, emotionally charged, or exaggerated language? Are there strong positive/negative sentiments toward a group, ideology, or issue?\n\n2. **Rhetorical bias**: Does the text use loaded language, name-calling, or manipulative rhetoric? Are there oversimplifications, strawman arguments, or exaggerated claims?\n\n3. **Framing bias**: Is information presented selectively to favor one perspective? Does it emphasize certain aspects while downplaying others to shape perception?\n\n4. **Ideological bias**: Does it emphasize certain aspects while downplaying others to shape perception? Does the article vilify opposing views rather than engaging with them fairly?\n\n5. **Unilateral coverage**: Does the article present multiple viewpoints (neutral) or only one side (hyperpartisan)? Are opposing arguments ignored, misrepresented, or dismissed?\n\n6. **Intent and Purpose**: Is the primary goal to inform objectively (neutral) or to persuade/mislead (hyperpartisan)? Does it present facts fairly, or does it push a clear agenda?\n\n7. Final prediction: Based on your previous considerations, classify the input as:\n - `neutral` (Neutral): Balanced, factual, and objective.\n - `one` (Hyperpartisan): Biased, one-sided, or manipulative.\n\nRemember to follow the output template. While generating the explanation for each reasoning step be coincise. Final Answer ==> [neutral or hyperpartisan]\n\n### Input: {}\n### Response:"
    },
    "fake_news_net": {
        "zero_shot_generic": "### Instruction: Determine if the text is fake news or not. If the news is true, the label is 'true', if the text is a fake news, the label is 'fake'. You have to choose one label and the output is only one label. To structure the output, follow the template in the example. \n\nOutput example: Final Answer ==> [fake or true]\n\n### Input: {}\n### Response:",
        "zero_shot_specific": "### Instruction: Fake news is defined as \"purposefully crafted, sensational, emotionally charged, misleading or totally fabricated information that mimics mainstream news\". Determine if the text is fake news or not. If the news is true, the label is 'true', if the text is a fake news, the label is 'fake'. You have to choose one label and the output is only one label. To structure the output, follow the template in the example. \n\nOutput example: Final Answer ==> [fake or true] \n\n### Input: {}\n### Response:",
        "few_shot": "### Instruction: Determine if the text is fake news or not. If the news is true, the label is 'true', if the text is a fake news, the label is 'fake'. You have to choose one label and the output is only one label. To structure the output, follow the template in the example. \n\nOutput example: Final Answer ==> [true or fake]\n\n### Input: {}\n\n### Response:",
        "codebook": "###Instruction: #Definition: Fake news detection identifies intentionally misleading content characterized by sensationalism, lack of credible sources, or manipulative language.\n\n### Task: Determine if the text is fake news or not. If the news is true, the label is 'true', if the text is a fake news, the label is 'fake'. To structure the output, follow the template in the example. \n\nOutput example: Final Answer ==> [true or fake].\n This is the codebook you have to use to perform the classification: \n\n### Detection Criteria:\n1. **Source Origin**\n   - Real: Established media, government sources\n   - Fake: Anonymous/unverifiable sources\n2. **Event Reporting**\n   - Real: Specific references, quantitative data\n   - Fake: Broad generalizations, unverifiable claims\n3. **Language Style**\n   - Real: Neutral, professional\n   - Fake: Sensationalized, clickbait\n4. **Entity Authenticity**\n   - Real: Named real-world entities\n   - Fake: Fictional/misspelled names\n5. **Claim Reliability**\n   - Real: Evidence-based\n   - Fake: Absurd/absolute claims\n6. **Emotional Tone**\n   - Real: Objective\n   - Fake: Emotional intensifiers\n7. **Source Credibility**\n   - Real: Verifiable\n   - Fake: Unknown/misleading domains\n8. **Political Balance**\n   - Real: Multi-perspective\n   - Fake: One-sided\n9. **Satire Markers**\n   - Real: No satire\n   - Fake: Absurd content\n10. **Conspiracy Indicators**\n    - Real: Supported theories\n    - Fake: Fringe conspiracy phrases\n\nOutput example:\n\nOutput example: Final Answer ==> [true or fake]\n\n### Input: {}\n### Response:",
        "cot": "### Instruction: Analyze the text for fake news using step-by-step reasoning. If the news is true, the label is 'true', if the text is a fake news, the label is 'fake'. You have to choose one label and the output is only one label. To structure the output, follow the template in the example. \n\nOutput example: Explanation: [Eplanation for each reasoning step]. Final Prediction: Final Answer ==> [true or fake]. \n\n### Reasoning Steps:\n1. **Lexical Analysis**\n   - Check for vague sourcing, absolutist language, logical fallacies\n2. **Sentiment Analysis**\n   - Identify polarizing/emotional language\n3. **Content Authenticity**\n   - Detect bot-like patterns, verify data\n4. **Framing Bias**\n   - Assess selective presentation\n5. Audience Analysis**\n   - Determine target audience and intent\n6. **Information Adequacy**\n   - Evaluate comprehensiveness and reliability. \n\nOutput example: Explanation: [Eplanation for each reasoning step]. Final Answer ==> [true or fake]. \n\n### Input: {}\n### Response:"
    },
    "fake_news_corpus_spanish": {
        "zero_shot_generic": "### InstrucciÃ³n: Determina si el texto es una noticia falsa o no. Si la noticia es verdadera, la etiqueta es 'true'; si es una noticia falsa, la etiqueta es 'fake'. Debes elegir una sola etiqueta y la salida debe ser solo una etiqueta. Para estructurar la salida, sigue el formato del ejemplo.\n\nEjemplo de salida: Final Answer ==> [fake or true]\n\n### Entrada: {}\n### Respuesta:",
        "zero_shot_specific": "### InstrucciÃ³n: Se define noticia falsa como \"informaciÃ³n elaborada intencionalmente, sensacionalista, emocional, engaÃ±osa o completamente inventada que imita a las noticias convencionales\". Determina si el texto es una noticia falsa o no. Si la noticia es verdadera, la etiqueta es 'true'; si es una noticia falsa, la etiqueta es 'fake'. Debes elegir una sola etiqueta y la salida debe ser solo una etiqueta. Para estructurar la salida, sigue el formato del ejemplo.\n\nEjemplo de salida: Final Answer ==> [fake or true]\n\n### Entrada: {}\n### Respuesta:",
        "few_shot": "### InstrucciÃ³n: Determina si el texto es una noticia falsa o no. Si la noticia es verdadera, la etiqueta es 'true'; si es una noticia falsa, la etiqueta es 'fake'. Debes elegir una sola etiqueta y la salida debe ser solo una etiqueta. Para estructurar la salida, sigue el formato del ejemplo.\n\nEjemplo de salida: Final Answer ==> [true or fake]\n\n### Entrada: {}\n\n### Respuesta:",
        "codebook": "### InstrucciÃ³n: #DefiniciÃ³n: La detecciÃ³n de noticias falsas identifica contenido intencionalmente engaÃ±oso caracterizado por sensacionalismo, falta de fuentes creÃ­bles o lenguaje manipulador.\n\n### Tarea: Determina si el texto es una noticia falsa o no. Si la noticia es verdadera, la etiqueta es 'true'; si es una noticia falsa, la etiqueta es 'fake'. Para estructurar la salida, sigue el formato del ejemplo.\n\nEjemplo de salida: Final Answer ==> [true or fake].\nEste es el manual que debes usar para realizar la clasificaciÃ³n:\n\n### Criterios de detecciÃ³n:\n1. **Origen de la fuente**\n   - Real: Medios establecidos, fuentes gubernamentales\n   - Fake: Fuentes anÃ³nimas/no verificables\n2. **Reporte del evento**\n   - Real: Referencias especÃ­ficas, datos cuantitativos\n   - Fake: Generalizaciones, afirmaciones no verificables\n3. **Estilo del lenguaje**\n   - Real: Neutral, profesional\n   - Fake: Sensacionalista, clickbait\n4. **Autenticidad de las entidades**\n   - Real: Entidades reales y nombradas\n   - Fake: Nombres ficticios o mal escritos\n5. **Fiabilidad de las afirmaciones**\n   - Real: Basadas en evidencia\n   - Fake: Afirmaciones absurdas/absolutas\n6. **Tono emocional**\n   - Real: Objetivo\n   - Fake: Intensificadores emocionales\n7. **Credibilidad de la fuente**\n   - Real: Verificable\n   - Fake: Dominios desconocidos o engaÃ±osos\n8. **Balance polÃ­tico**\n   - Real: Perspectivas mÃºltiples\n   - Fake: Unilateral\n9. **Indicadores de sÃ¡tira**\n   - Real: Sin sÃ¡tira\n   - Fake: Contenido absurdo\n10. **Indicadores de conspiraciÃ³n**\n    - Real: TeorÃ­as respaldadas\n    - Fake: Frases de conspiraciÃ³n marginales\n\nEjemplo de salida: Final Answer ==> [true or fake]\n\n### Entrada: {}\n### Respuesta:",
        "cot": "### InstrucciÃ³n: Analiza el texto para detectar noticias falsas utilizando un razonamiento paso a paso. Si la noticia es verdadera, la etiqueta es 'true'; si es una noticia falsa, la etiqueta es 'fake'. Debes elegir una sola etiqueta y la salida debe ser solo una etiqueta. Para estructurar la salida, sigue el formato del ejemplo.\n\nEjemplo de salida: ExplicaciÃ³n: [ExplicaciÃ³n para cada paso del razonamiento]. PredicciÃ³n final: Final Answer ==> [true or fake].\n\n### Pasos de razonamiento:\n1. **AnÃ¡lisis lÃ©xico**\n   - Verificar lenguaje absoluto, falacias lÃ³gicas, fuentes vagas\n2. **AnÃ¡lisis de sentimiento**\n   - Identificar lenguaje emocional o polarizante\n3. **Autenticidad del contenido**\n   - Detectar patrones automatizados, verificar datos\n4. **Sesgo de encuadre**\n   - Evaluar presentaciÃ³n selectiva\n5. **AnÃ¡lisis de la audiencia**\n   - Determinar pÃºblico objetivo e intenciÃ³n\n6. **AdecuaciÃ³n informativa**\n   - Evaluar exhaustividad y fiabilidad\n\nEjemplo de salida: ExplicaciÃ³n: [ExplicaciÃ³n para cada paso del razonamiento]. Final Answer ==> [true or fake].\n\n### Entrada: {}\n### Respuesta:"
    },
    "fake_br_corpus": {
        "zero_shot_generic": "### InstruÃ§Ã£o: Determine se o texto Ã© uma notÃ­cia falsa ou nÃ£o. Se a notÃ­cia for verdadeira, o rÃ³tulo Ã© 'true'; se for uma notÃ­cia falsa, o rÃ³tulo Ã© 'fake'. VocÃª deve escolher apenas um rÃ³tulo e a saÃ­da deve conter apenas esse rÃ³tulo. Para estruturar a saÃ­da, siga o modelo do exemplo.\n\nExemplo de saÃ­da: Final Answer ==> [fake or true]\n\n### Entrada: {}\n### Resposta:",
        "zero_shot_specific": "### InstruÃ§Ã£o: NotÃ­cia falsa Ã© definida como \"informaÃ§Ã£o propositalmente criada, sensacionalista, emocionalmente carregada, enganosa ou totalmente fabricada que imita notÃ­cias tradicionais\". Determine se o texto Ã© uma notÃ­cia falsa ou nÃ£o. Se a notÃ­cia for verdadeira, o rÃ³tulo Ã© 'true'; se for falsa, o rÃ³tulo Ã© 'fake'. VocÃª deve escolher apenas um rÃ³tulo e a saÃ­da deve conter apenas esse rÃ³tulo. Para estruturar a saÃ­da, siga o modelo do exemplo.\n\nExemplo de saÃ­da: Final Answer ==> [fake or true]\n\n### Entrada: {}\n### Resposta:",
        "few_shot": "### InstruÃ§Ã£o: Determine se o texto Ã© uma notÃ­cia falsa ou nÃ£o. Se a notÃ­cia for verdadeira, o rÃ³tulo Ã© 'true'; se for falsa, o rÃ³tulo Ã© 'fake'. VocÃª deve escolher apenas um rÃ³tulo e a saÃ­da deve conter apenas esse rÃ³tulo. Para estruturar a saÃ­da, siga o modelo do exemplo.\n\nExemplo de saÃ­da: Final Answer ==> [true or fake]\n\n### Entrada: {}\n\n### Resposta:",
        "codebook": "### InstruÃ§Ã£o: #DefiniÃ§Ã£o: A detecÃ§Ã£o de notÃ­cias falsas identifica conteÃºdos intencionalmente enganosos caracterizados por sensacionalismo, falta de fontes confiÃ¡veis ou linguagem manipuladora.\n\n### Tarefa: Determine se o texto Ã© uma notÃ­cia falsa ou nÃ£o. Se a notÃ­cia for verdadeira, o rÃ³tulo Ã© 'true'; se for falsa, o rÃ³tulo Ã© 'fake'. Para estruturar a saÃ­da, siga o modelo do exemplo.\n\nExemplo de saÃ­da: Final Answer ==> [true or fake].\nEste Ã© o manual que vocÃª deve usar para realizar a classificaÃ§Ã£o:\n\n### CritÃ©rios de detecÃ§Ã£o:\n1. **Origem da fonte**\n   - Real: MÃ­dia estabelecida, fontes governamentais\n   - Fake: Fontes anÃ´nimas ou nÃ£o verificÃ¡veis\n2. **Relato do evento**\n   - Real: ReferÃªncias especÃ­ficas, dados quantitativos\n   - Fake: GeneralizaÃ§Ãµes amplas, alegaÃ§Ãµes nÃ£o verificÃ¡veis\n3. **Estilo de linguagem**\n   - Real: Neutro, profissional\n   - Fake: Sensacionalista, clickbait\n4. **Autenticidade das entidades**\n   - Real: Entidades reais nomeadas\n   - Fake: Nomes fictÃ­cios ou com erros ortogrÃ¡ficos\n5. **Confiabilidade das alegaÃ§Ãµes**\n   - Real: Baseadas em evidÃªncias\n   - Fake: AlegaÃ§Ãµes absurdas ou absolutas\n6. **Tom emocional**\n   - Real: Objetivo\n   - Fake: Intensificadores emocionais\n7. **Credibilidade da fonte**\n   - Real: VerificÃ¡vel\n   - Fake: DomÃ­nios desconhecidos ou enganosos\n8. **EquilÃ­brio polÃ­tico**\n   - Real: MÃºltiplas perspectivas\n   - Fake: Unilateral\n9. **Indicadores de sÃ¡tira**\n   - Real: Sem sÃ¡tira\n   - Fake: ConteÃºdo absurdo\n10. **Indicadores de conspiraÃ§Ã£o**\n    - Real: Teorias respaldadas\n    - Fake: Frases de conspiraÃ§Ã£o marginalizadas\n\nExemplo de saÃ­da: Final Answer ==> [true or fake]\n\n### Entrada: {}\n### Resposta:",
        "cot": "### InstruÃ§Ã£o: Analise o texto para detectar notÃ­cias falsas usando um raciocÃ­nio passo a passo. Se a notÃ­cia for verdadeira, o rÃ³tulo Ã© 'true'; se for falsa, o rÃ³tulo Ã© 'fake'. VocÃª deve escolher apenas um rÃ³tulo e a saÃ­da deve conter apenas esse rÃ³tulo. Para estruturar a saÃ­da, siga o modelo do exemplo.\n\nExemplo de saÃ­da: ExplicaÃ§Ã£o: [ExplicaÃ§Ã£o para cada passo do raciocÃ­nio]. PrevisÃ£o final: Final Answer ==> [true or fake].\n\n### Etapas de raciocÃ­nio:\n1. **AnÃ¡lise lexical**\n   - Verifique linguagem vaga, absolutismos, falÃ¡cias lÃ³gicas\n2. **AnÃ¡lise de sentimento**\n   - Identifique linguagem polarizadora/emocional\n3. **Autenticidade do conteÃºdo**\n   - Detecte padrÃµes automatizados, verifique dados\n4. **ViÃ©s de enquadramento**\n   - Avalie apresentaÃ§Ã£o seletiva\n5. **AnÃ¡lise de audiÃªncia**\n   - Determine o pÃºblico-alvo e a intenÃ§Ã£o\n6. **AdequaÃ§Ã£o das informaÃ§Ãµes**\n   - Avalie abrangÃªncia e confiabilidade\n\nExemplo de saÃ­da: ExplicaÃ§Ã£o: [ExplicaÃ§Ã£o para cada passo do raciocÃ­nio]. Final Answer ==> [true or fake].\n\n### Entrada: {}\n### Resposta:"
    },
    "all_sides": {
        "zero_shot_generic": "###Instruction: Determine the political leaning of the headline. The possible choices are: 'left' if the article is left-wing, 'center' if the political leaning is from the center, 'right' if the article is right-wing'. Output only one string following the template.\n\nOutput example:\nFinal Answer ==> [left or center or right]\n\n### Input: {}\n### Response:",
        "zero_shot_specific": "###Instruction: Left-wing ideologies and moral values often include support for social equality, environmentalism, social justice, labor rights, and progressive taxation. Center ideologies and moral values often focus on a balance between market and social justice, pragmatism, and incremental reform. Right-wing ideologies and moral values often emphasize tradition, free market capitalism, individualism, and a limited role of government.  Detect the political leaning of the headline. Determine the political leaning of the headline. The possible choices are: 'left' if the article is left-wing, 'center' if the political leaning is from the center, 'right' if the article is right-wing'. Output only one string following the template.\n\nOutput example:\nFinal Answer ==> [left or center or right]\n\n### Input: {}\n### Response:",
        "few_shot": "###Instruction: Determine the political leaning of the headline. The possible choices are: 'left' if the article is left-wing, 'center' if the political leaning is from the center, 'right' if the article is right-wing'. Output only one string following the template.\n\nOutput example:\nFinal Answer ==> [left or center or right]\n\n### Input: {}\n### Response:",
        "codebook": "###Instruction: #Definition: Left-wing ideologies and moral values often include support for social equality, environmentalism, social justice, labor rights, and progressive taxation. Center ideologies and moral values often focus on a balance between market and social justice, pragmatism, and incremental reform. Right-wing ideologies and moral values often emphasize tradition, free market capitalism, individualism, and a limited role of government. #Task: Determine the political leaning of the headline. The possible choices are: 'left' if the article is left-wing, 'center' if the political leaning is from the center, 'right' if the article is right-wing'. Output only one string following the template.\n\nOutput example:\nFinal Answer ==> [left or center or right]. This is the codebook you have to use to perform the classification:          | Aspect               | LEFT (0)                                                                                                    | CENTER (1)                                                                                           | RIGHT (2)                                                                                                   |\n|----------------------|------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------|\n| Ideological Roots    | Progressive, liberal, social justice, democratic socialism                                                       | Moderation, institutionalism, nonpartisan pragmatism                                                     | Conservatism, libertarianism, nationalism                                                                        |\n| Key Policy Agendas   | - Universal healthcare (e.g., Medicare for All)  \n- Climate action (Green New Deal)  \n- Wealth tax \n- Labor rights and unions \n- Police reform / abolition  \n- Student debt cancellation | - Bipartisanship \n- Maintaining status quo institutions \n- Incremental reforms \n- Fiscal responsibility | - Tax cuts and deregulation \n- Gun rights (2nd Amendment) \n- Strict immigration laws \n- Pro-life policies \n- â€œLaw and orderâ€ stance |\n| Common Language      | â€œSystemic inequalityâ€, â€œworking classâ€, â€œcorporate greedâ€, â€œclimate justiceâ€, â€œracial equityâ€, â€œliving wageâ€    | â€œBalanced reportingâ€, â€œnonpartisanâ€, â€œmoderate viewsâ€, â€œpragmatic compromiseâ€                             | â€œTraditional valuesâ€, â€œpatrioticâ€, â€œborder securityâ€, â€œradical leftâ€, â€œAmerican greatnessâ€, â€œfamily valuesâ€      |\n| View of Government   | Government should be a tool for equity, regulation, and public welfare                                          | Government as a stabilizer and mediator                                                                   | Government should be limited; strong military and police; personal freedom prioritized                           |\n| Typical Tone         | Activist, morally urgent, critical of status quo                                                                | Analytical, factual, restrained                                                                           | Assertive, confrontational, morally charged rhetoric against liberal or globalist forces                         |\n| Political Figures Supported | Bernie Sanders, Alexandria Ocasio-Cortez, Elizabeth Warren                                               | Joe Biden, Barack Obama, moderate Democrats/Republicans                                                   | Donald Trump, Ron DeSantis, Mitch McConnell, populist or libertarian Republicans                                 |\n| Narrative Framing    | Victim-centered, systemic critiques, emphasis on social movements                                               | Both-sides perspectives, institutional trust                                                              | Individual responsibility, fear of decline, anti-elite, nationalist pride                                        |\n| Targeted Criticism   | Corporations, police/military complex, conservative media, Republicans                                          | Extremes on both sides, especially ideological polarizations                                               | Liberal elites, â€œmainstream mediaâ€, progressive activists, Democratic establishment                              |\n| Media Examples (U.S.)| The Nation, Democracy Now!, HuffPost, MSNBC (opinion)                                                           | Reuters, Associated Press, NPR, PBS                                                                        | Fox News, Breitbart, The Daily Caller, The Federalist                                                            |\n\n### Output template example:\nFinal Answer ==> [left or center or right]\n\n### Input: {}\n### Response:",
        "cot": "###Instruction: Determine the political leaning of the headline by following the reasoning steps below. You'll return the explanation and the output of the label. The output will be only one label like this example: 'number'. The possible choices are: 'left' if the article is left-wing, 'center' if the political leaning is from the center, 'right' if the article is right-wing'. Reason step by step: 1. Identify key words and phrases: list of words or phrases that might indicate political bias. 2. Sentiment analysis: Analyze the tone and the language to see if there are polarizing words, or emotional language. 3. Are there any rhetorical devices used? (e.g., hyperbole, loaded questions). 4. Look for policy implications: Does the headline suggest support for or opposition to specific policies? Are there any implicit assumptions about political or economic systems? 5. Identify target audience: Who seems to be the intended audience for this headline? 6. Left-wing hyperpartisan: Consider you are a left-wing reader. Would you consider this article as hyperpartisan to your political stance? [Follow the instructions from 1 to 5.] 7. Right-wing hyperpartisan: Consider you are a right-wing reader. Would you consider this article as hyperpartisan to your political stance? [Follow the instructions from 1 to 5.] 8. Consider omissions and emphasis: What information is emphasized, and what might be omitted? How might this emphasis or omission indicate bias? 9. Final prediction: INTEGER LABEL. The output will be in this format. Remember to use all reasoning steps followed by <end> to write a coincise explanation: Example output: # Key words: EXPLANATION <end> # Sentiment analysis: EXPLANATION <end> # Policy implications: EXPLANATION <end> # Target audience: EXPLANATION <end> # Left-wing hyperpartisan: EXPLANATION <end> # Right-wing hyperpartisan: EXPLANATION <end> # Omissions and emphasis: EXPLANATION <end> \n#Final Answer ==> [left or center or right]\n\n### Input: {}\n### Response:"
    },
    "clef_3a": {
        "zero_shot_generic": "###Instruction: Determine the political leaning of the headline. The possible choices are: 'left' if the article is left-wing, 'center' if the political leaning is from the center, 'right' if the article is right-wing'. Output only one string following the template.\n\nOutput example:\nFinal Answer ==> [left or center or right]\n\n### Input: {}\n### Response:",
        "zero_shot_specific": "###Instruction: Left-wing ideologies and moral values often include support for social equality, environmentalism, social justice, labor rights, and progressive taxation. Center ideologies and moral values often focus on a balance between market and social justice, pragmatism, and incremental reform. Right-wing ideologies and moral values often emphasize tradition, free market capitalism, individualism, and a limited role of government.  Detect the political leaning of the headline. Determine the political leaning of the headline. The possible choices are: 'left' if the article is left-wing, 'center' if the political leaning is from the center, 'right' if the article is right-wing'. Output only one string following the template.\n\nOutput example:\nFinal Answer ==> [left or center or right]\n\n### Input: {}\n### Response:",
        "few_shot": "###Instruction: Determine the political leaning of the headline. The possible choices are: 'left' if the article is left-wing, 'center' if the political leaning is from the center, 'right' if the article is right-wing'. Output only one string following the template.\n\nOutput example:\nFinal Answer ==> [left or center or right]\n\n### Input: {}\n### Response:",
        "codebook": "###Instruction: #Definition: Left-wing ideologies and moral values often include support for social equality, environmentalism, social justice, labor rights, and progressive taxation. Center ideologies and moral values often focus on a balance between market and social justice, pragmatism, and incremental reform. Right-wing ideologies and moral values often emphasize tradition, free market capitalism, individualism, and a limited role of government. #Task: Determine the political leaning of the headline. The possible choices are: 'left' if the article is left-wing, 'center' if the political leaning is from the center, 'right' if the article is right-wing'. Output only one string following the template.\n\nOutput example:\nFinal Answer ==> [left or center or right]. This is the codebook you have to use to perform the classification:          | Aspect               | LEFT (0)                                                                                                    | CENTER (1)                                                                                           | RIGHT (2)                                                                                                   |\n|----------------------|------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------|\n| Ideological Roots    | Progressive, liberal, social justice, democratic socialism                                                       | Moderation, institutionalism, nonpartisan pragmatism                                                     | Conservatism, libertarianism, nationalism                                                                        |\n| Key Policy Agendas   | - Universal healthcare (e.g., Medicare for All)  \n- Climate action (Green New Deal)  \n- Wealth tax \n- Labor rights and unions \n- Police reform / abolition  \n- Student debt cancellation | - Bipartisanship \n- Maintaining status quo institutions \n- Incremental reforms \n- Fiscal responsibility | - Tax cuts and deregulation \n- Gun rights (2nd Amendment) \n- Strict immigration laws \n- Pro-life policies \n- â€œLaw and orderâ€ stance |\n| Common Language      | â€œSystemic inequalityâ€, â€œworking classâ€, â€œcorporate greedâ€, â€œclimate justiceâ€, â€œracial equityâ€, â€œliving wageâ€    | â€œBalanced reportingâ€, â€œnonpartisanâ€, â€œmoderate viewsâ€, â€œpragmatic compromiseâ€                             | â€œTraditional valuesâ€, â€œpatrioticâ€, â€œborder securityâ€, â€œradical leftâ€, â€œAmerican greatnessâ€, â€œfamily valuesâ€      |\n| View of Government   | Government should be a tool for equity, regulation, and public welfare                                          | Government as a stabilizer and mediator                                                                   | Government should be limited; strong military and police; personal freedom prioritized                           |\n| Typical Tone         | Activist, morally urgent, critical of status quo                                                                | Analytical, factual, restrained                                                                           | Assertive, confrontational, morally charged rhetoric against liberal or globalist forces                         |\n| Political Figures Supported | Bernie Sanders, Alexandria Ocasio-Cortez, Elizabeth Warren                                               | Joe Biden, Barack Obama, moderate Democrats/Republicans                                                   | Donald Trump, Ron DeSantis, Mitch McConnell, populist or libertarian Republicans                                 |\n| Narrative Framing    | Victim-centered, systemic critiques, emphasis on social movements                                               | Both-sides perspectives, institutional trust                                                              | Individual responsibility, fear of decline, anti-elite, nationalist pride                                        |\n| Targeted Criticism   | Corporations, police/military complex, conservative media, Republicans                                          | Extremes on both sides, especially ideological polarizations                                               | Liberal elites, â€œmainstream mediaâ€, progressive activists, Democratic establishment                              |\n| Media Examples (U.S.)| The Nation, Democracy Now!, HuffPost, MSNBC (opinion)                                                           | Reuters, Associated Press, NPR, PBS                                                                        | Fox News, Breitbart, The Daily Caller, The Federalist                                                            |\n\n### Output template example:\nFinal Answer ==> [left or center or right]\n\n### Input: {}\n### Response:",
        "cot": "###Instruction: Determine the political leaning of the headline by following the reasoning steps below. You'll return the explanation and the output of the label. The output will be only one label like this example: 'number'. The possible choices are: 'left' if the article is left-wing, 'center' if the political leaning is from the center, 'right' if the article is right-wing'. Reason step by step: 1. Identify key words and phrases: list of words or phrases that might indicate political bias. 2. Sentiment analysis: Analyze the tone and the language to see if there are polarizing words, or emotional language. 3. Are there any rhetorical devices used? (e.g., hyperbole, loaded questions). 4. Look for policy implications: Does the headline suggest support for or opposition to specific policies? Are there any implicit assumptions about political or economic systems? 5. Identify target audience: Who seems to be the intended audience for this headline? 6. Left-wing hyperpartisan: Consider you are a left-wing reader. Would you consider this article as hyperpartisan to your political stance? [Follow the instructions from 1 to 5.] 7. Right-wing hyperpartisan: Consider you are a right-wing reader. Would you consider this article as hyperpartisan to your political stance? [Follow the instructions from 1 to 5.] 8. Consider omissions and emphasis: What information is emphasized, and what might be omitted? How might this emphasis or omission indicate bias? 9. Final prediction: INTEGER LABEL. The output will be in this format. Remember to use all reasoning steps followed by <end> to write a coincise explanation: Example output: # Key words: EXPLANATION <end> # Sentiment analysis: EXPLANATION <end> # Policy implications: EXPLANATION <end> # Target audience: EXPLANATION <end> # Left-wing hyperpartisan: EXPLANATION <end> # Right-wing hyperpartisan: EXPLANATION <end> # Omissions and emphasis: EXPLANATION <end> \n#Final Answer ==> [left or center or right]\n\n### Input: {}\n### Response:"
    },
    "clef_1c_en": {
        "zero_shot_generic": "### Instruction: Detect if a tweet is harmful to society or not. Choose one label: if the content is harmful, the label is: 'harmul'; whereas if the content is not harmful the label is: 'not'. Output only one string following the template.\n\nOutput example:\nFinal Answer ==> [harmful or not]\n\n### Input: {}\n### Response:",
        "zero_shot_specific": "### Instruction: Harmful tweet is a post on the social media platform Twitter that can cause distress, harm, or damage to individuals, groups, or society. This type of tweet may include content that is abusive, offensive, defamatory, threatening, or incites violence against the policies to contain the spread of COVID-19. Additionally, it may spread false information, contribute to cyberbullying, or perpetuate hate speech and discrimination. Harmful tweets can negatively impact mental health, reputations, and community safety. Detect if a tweet is harmful to society or not. Choose one label: if the content is harmful, the label is:'harmul'; while if the content is not harmful the label is: 'not'. Output only one string following the template.\n\nOutput example:\n\nFinal Answer ==> [harmful or not] \n\n###Input: {} \n\n###Response:",
        "few_shot": "### Instruction: Detect if a tweet is harmful to society or not. Choose one label: if the content is harmful, the label is: 'harmul'; whereas if the content is not harmful the label is: 'not'. Output only one string following the template.\n\nOutput example:\nFinal Answer ==> [harmful or not]\n\n### Input: {}\n### Response:",
        "codebook": "### Instruction: #Definition: Harmful tweet is a post on the social media platform Twitter that can cause distress, harm, or damage to individuals, groups, or society. This type of tweet may include content that is abusive, offensive, defamatory, threatening, or incites violence against the policies to contain the spread of COVID-19. Additionally, it may spread false information, contribute to cyberbullying, or perpetuate hate speech and discrimination. Harmful tweets can negatively impact mental health, reputations, and community safety. #Task: Read carefully the codebook and detect if a tweet is harmful to society or not. Choose one label: if the content is harmful, the label is 'harmul'; whereas if the content is not harmful the label is 'not'. Output only one string following the template.\n\nOutput example:\n\nFinal Answer ==> [harmful or not] \nThis is the codebook: | Label | Class       | Definition                                                                                         | Typical Content Patterns                                                                                                                                         |\n|-------|--------------|--------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| not     | Not Harmful  | The tweet provides factual, supportive, or neutral information about COVID-19.                  | - Promotes vaccinations, masking, or safety \n- Shares news from reliable sources (WHO, CDC) \n- Describes personal experiences without disinformation         |\n| 1     | Harmful      | The tweet contains disinformation, conspiracy theories, or medically incorrect claims.           | - Claims vaccines are deadly or part of a conspiracy \n- Encourages rejection of public health guidance \n- Spreads pseudoscience or political hoaxes         |\n\n| Aspect              | Description of Harmful Characteristics                                                                                     |\n|---------------------|----------------------------------------------------------------------------------------------------------------------------|\n| Conspiracy Theory   | References to population control, â€œplandemicâ€, 5G causes COVID, microchips in vaccines                                     |\n| Distrust in Science | Discredits CDC/WHO, claims that mainstream medicine is false or corrupt                                                     |\n| Alternative Cures   | Promotes ivermectin, bleach, natural remedies as vaccine alternatives without evidence                                     |\n| Anti-Vaccine        | Claims vaccines are unsafe, rushed, or part of a control agenda                                                            |\n| Hoax Narrative      | Declares COVID-19 is fake, exaggerated, or invented by governments                                                         |\n| Call to Action      | Urges followers to ignore mandates, avoid vaccination, or resist masking                                                   |\n| Language Style      | Emotionally charged, sarcastic, or mocking tone; often uses ALL CAPS, emojis (ðŸ’‰ðŸ§¬ðŸ¦ ), hashtags like #NoVax #Plandemic      |\n\n| Linguistic Features      | Harmful                                       | Not Harmful                                       |\n|--------------------------|-----------------------------------------------|---------------------------------------------------|\n| Use of hashtags          | #plandemic, #NoVax, #scamdemic                | #GetVaccinated, #StaySafe                         |\n| Source credibility       | Anonymous sources, influencer claims          | WHO, CDC, news outlets                            |\n| Personal stories         | Claims of side effects or hoaxes              | Stories of recovery, gratitude for vaccines       |\n| Tone                     | Alarmist, rebellious, sarcastic               | Informative, cautious, or appreciative            |. \n### Output template example: Final Answer ==> [harmful or not] \n\n###Input: {}\n\n###Response:",
        "cot": "### Instruction: Detect if a tweet is harmful to society or not. Choose one label: if the content is harmful, the label is:'harmul'; while if the content is not harmful the label is: 'not'. Output only one string following the template.\n\nOutput example:\nFinal Answer ==> [harmful or not]. Reason stepy by step: 1.**Leixcal analysis** Identify keywords and phrases: Make a list of words or phrases that may contain harmful information and intent. 2.**Sentiment analysis**: Analyze the tone and language to see if there is unintentional or intentional harmful behavior, words, or emotional language. 3.**Audience** Identify the target audience: Who seems to be the target audience for this tweet? 4. **Threats and harassment**: Direct or veiled threats of violence, physical harm, or harassment. This includes revealing personal information (doxing), stalking, or inciting others to commit harassment. 5.**Hostile speech**: Expressions of hatred, intolerance or prejudice against specific groups. This can manifest as dehumanizing language, calls for violence or promotion of discriminatory ideologies. 6.**Disinformation and false information**: The spreading of false or misleading information, often with the intention to mislead or manipulate. This can include conspiracy theories, fake news or manipulated media. # Cyberbullying: Aggressive or deliberate behavior using electronic communications to harm, humiliate or threaten an individual. 7.Coincise explanation for each step:[Explanation]. Final Answer ==> [harmful or not] ###Input:{}   #### Response:"
    },
    "clef_1c_bg": {
        "zero_shot_generic": "### Ð˜Ð½ÑÑ‚Ñ€ÑƒÐºÑ†Ð¸Ñ: ÐžÑ‚ÐºÑ€Ð¸Ð¹Ñ‚Ðµ Ð´Ð°Ð»Ð¸ Ñ‚ÑƒÐ¸Ñ‚ÑŠÑ‚ Ðµ Ð²Ñ€ÐµÐ´ÐµÐ½ Ð·Ð° Ð¾Ð±Ñ‰ÐµÑÑ‚Ð²Ð¾Ñ‚Ð¾ Ð¸Ð»Ð¸ Ð½Ðµ. Ð˜Ð·Ð±ÐµÑ€ÐµÑ‚Ðµ ÐµÐ´Ð¸Ð½ ÐµÑ‚Ð¸ÐºÐµÑ‚: Ð°ÐºÐ¾ ÑÑŠÐ´ÑŠÑ€Ð¶Ð°Ð½Ð¸ÐµÑ‚Ð¾ Ðµ Ð²Ñ€ÐµÐ´Ð½Ð¾, ÐµÑ‚Ð¸ÐºÐµÑ‚ÑŠÑ‚ Ðµ: 'harmful'; Ð°ÐºÐ¾ ÑÑŠÐ´ÑŠÑ€Ð¶Ð°Ð½Ð¸ÐµÑ‚Ð¾ Ð½Ðµ Ðµ Ð²Ñ€ÐµÐ´Ð½Ð¾, ÐµÑ‚Ð¸ÐºÐµÑ‚ÑŠÑ‚ Ðµ: 'not'. Ð˜Ð·Ð²ÐµÐ´ÐµÑ‚Ðµ ÑÐ°Ð¼Ð¾ ÐµÐ´Ð¸Ð½ Ð½Ð¸Ð·, ÑÐ»ÐµÐ´Ð²Ð°Ð¹ÐºÐ¸ ÑˆÐ°Ð±Ð»Ð¾Ð½Ð°.\n\nÐŸÑ€Ð¸Ð¼ÐµÑ€ Ð·Ð° Ð¸Ð·Ñ…Ð¾Ð´:\nFinal Answer ==> [harmful or not]\n\n### Ð’Ñ…Ð¾Ð´: {}\n### ÐžÑ‚Ð³Ð¾Ð²Ð¾Ñ€:",
        "zero_shot_specific": "### Ð˜Ð½ÑÑ‚Ñ€ÑƒÐºÑ†Ð¸Ñ: Ð’Ñ€ÐµÐ´ÐµÐ½ Ñ‚ÑƒÐ¸Ñ‚ Ðµ Ð¿ÑƒÐ±Ð»Ð¸ÐºÐ°Ñ†Ð¸Ñ Ð² ÑÐ¾Ñ†Ð¸Ð°Ð»Ð½Ð°Ñ‚Ð° Ð¼Ñ€ÐµÐ¶Ð° Twitter, ÐºÐ¾ÑÑ‚Ð¾ Ð¼Ð¾Ð¶Ðµ Ð´Ð° Ð¿Ñ€Ð¸Ñ‡Ð¸Ð½Ð¸ ÑÑ‚Ñ€Ð°Ð´Ð°Ð½Ð¸Ðµ, Ð²Ñ€ÐµÐ´Ð° Ð¸Ð»Ð¸ Ñ‰ÐµÑ‚Ð¸ Ð½Ð° Ð¸Ð½Ð´Ð¸Ð²Ð¸Ð´Ð¸, Ð³Ñ€ÑƒÐ¿Ð¸ Ð¸Ð»Ð¸ Ð¾Ð±Ñ‰ÐµÑÑ‚Ð²Ð¾Ñ‚Ð¾. Ð¢Ð¾Ð·Ð¸ Ñ‚Ð¸Ð¿ Ñ‚ÑƒÐ¸Ñ‚ Ð¼Ð¾Ð¶Ðµ Ð´Ð° Ð²ÐºÐ»ÑŽÑ‡Ð²Ð° ÑÑŠÐ´ÑŠÑ€Ð¶Ð°Ð½Ð¸Ðµ, ÐºÐ¾ÐµÑ‚Ð¾ Ðµ Ð¾Ð±Ð¸Ð´Ð½Ð¾, ÐºÐ»ÐµÐ²ÐµÑ‚Ð½Ð¸Ñ‡ÐµÑÐºÐ¾, Ð·Ð°Ð¿Ð»Ð°ÑˆÐ¸Ñ‚ÐµÐ»Ð½Ð¾ Ð¸Ð»Ð¸ Ð¿Ð¾Ð´Ð±ÑƒÐ¶Ð´Ð° ÐºÑŠÐ¼ Ð½Ð°ÑÐ¸Ð»Ð¸Ðµ ÑÑ€ÐµÑ‰Ñƒ Ð¿Ð¾Ð»Ð¸Ñ‚Ð¸ÐºÐ¸Ñ‚Ðµ Ð·Ð° Ð¾Ð³Ñ€Ð°Ð½Ð¸Ñ‡Ð°Ð²Ð°Ð½Ðµ Ð½Ð° Ñ€Ð°Ð·Ð¿Ñ€Ð¾ÑÑ‚Ñ€Ð°Ð½ÐµÐ½Ð¸ÐµÑ‚Ð¾ Ð½Ð° COVID-19. ÐžÑÐ²ÐµÐ½ Ñ‚Ð¾Ð²Ð°, Ð¼Ð¾Ð¶Ðµ Ð´Ð° Ñ€Ð°Ð·Ð¿Ñ€Ð¾ÑÑ‚Ñ€Ð°Ð½ÑÐ²Ð° Ñ„Ð°Ð»ÑˆÐ¸Ð²Ð° Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ, Ð´Ð° Ð´Ð¾Ð¿Ñ€Ð¸Ð½Ð°ÑÑ Ð·Ð° ÐºÐ¸Ð±ÐµÑ€Ñ‚Ð¾Ñ€Ð¼Ð¾Ð· Ð¸Ð»Ð¸ Ð´Ð° Ð¿Ð¾Ð´Ð´ÑŠÑ€Ð¶Ð° Ñ€ÐµÑ‡ Ð½Ð° Ð¾Ð¼Ñ€Ð°Ð·Ð° Ð¸ Ð´Ð¸ÑÐºÑ€Ð¸Ð¼Ð¸Ð½Ð°Ñ†Ð¸Ñ. Ð’Ñ€ÐµÐ´Ð½Ð¸Ñ‚Ðµ Ñ‚ÑƒÐ¸Ñ‚Ð¾Ð²Ðµ Ð¼Ð¾Ð³Ð°Ñ‚ Ð´Ð° Ð¸Ð¼Ð°Ñ‚ Ð¾Ñ‚Ñ€Ð¸Ñ†Ð°Ñ‚ÐµÐ»Ð½Ð¾ Ð²ÑŠÐ·Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ðµ Ð²ÑŠÑ€Ñ…Ñƒ Ð¿ÑÐ¸Ñ…Ð¸Ñ‡Ð½Ð¾Ñ‚Ð¾ Ð·Ð´Ñ€Ð°Ð²Ðµ, Ñ€ÐµÐ¿ÑƒÑ‚Ð°Ñ†Ð¸Ð¸Ñ‚Ðµ Ð¸ Ð¾Ð±Ñ‰ÐµÑÑ‚Ð²ÐµÐ½Ð°Ñ‚Ð° Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾ÑÑ‚. ÐžÑ‚ÐºÑ€Ð¸Ð¹Ñ‚Ðµ Ð´Ð°Ð»Ð¸ Ñ‚ÑƒÐ¸Ñ‚ÑŠÑ‚ Ðµ Ð²Ñ€ÐµÐ´ÐµÐ½ Ð·Ð° Ð¾Ð±Ñ‰ÐµÑÑ‚Ð²Ð¾Ñ‚Ð¾ Ð¸Ð»Ð¸ Ð½Ðµ. Ð˜Ð·Ð±ÐµÑ€ÐµÑ‚Ðµ ÐµÐ´Ð¸Ð½ ÐµÑ‚Ð¸ÐºÐµÑ‚: Ð°ÐºÐ¾ ÑÑŠÐ´ÑŠÑ€Ð¶Ð°Ð½Ð¸ÐµÑ‚Ð¾ Ðµ Ð²Ñ€ÐµÐ´Ð½Ð¾, ÐµÑ‚Ð¸ÐºÐµÑ‚ÑŠÑ‚ Ðµ: 'harmful'; Ð°ÐºÐ¾ ÑÑŠÐ´ÑŠÑ€Ð¶Ð°Ð½Ð¸ÐµÑ‚Ð¾ Ð½Ðµ Ðµ Ð²Ñ€ÐµÐ´Ð½Ð¾, ÐµÑ‚Ð¸ÐºÐµÑ‚ÑŠÑ‚ Ðµ: 'not'. Ð˜Ð·Ð²ÐµÐ´ÐµÑ‚Ðµ ÑÐ°Ð¼Ð¾ ÐµÐ´Ð¸Ð½ Ð½Ð¸Ð·, ÑÐ»ÐµÐ´Ð²Ð°Ð¹ÐºÐ¸ ÑˆÐ°Ð±Ð»Ð¾Ð½Ð°.\n\nÐŸÑ€Ð¸Ð¼ÐµÑ€ Ð·Ð° Ð¸Ð·Ñ…Ð¾Ð´:\nFinal Answer ==> [harmful or not]\n\n### Ð’Ñ…Ð¾Ð´: {}\n### ÐžÑ‚Ð³Ð¾Ð²Ð¾Ñ€:",
        "few_shot": "### Ð˜Ð½ÑÑ‚Ñ€ÑƒÐºÑ†Ð¸Ñ: ÐžÑ‚ÐºÑ€Ð¸Ð¹Ñ‚Ðµ Ð´Ð°Ð»Ð¸ Ñ‚ÑƒÐ¸Ñ‚ÑŠÑ‚ Ðµ Ð²Ñ€ÐµÐ´ÐµÐ½ Ð·Ð° Ð¾Ð±Ñ‰ÐµÑÑ‚Ð²Ð¾Ñ‚Ð¾ Ð¸Ð»Ð¸ Ð½Ðµ. Ð˜Ð·Ð±ÐµÑ€ÐµÑ‚Ðµ ÐµÐ´Ð¸Ð½ ÐµÑ‚Ð¸ÐºÐµÑ‚: Ð°ÐºÐ¾ ÑÑŠÐ´ÑŠÑ€Ð¶Ð°Ð½Ð¸ÐµÑ‚Ð¾ Ðµ Ð²Ñ€ÐµÐ´Ð½Ð¾, ÐµÑ‚Ð¸ÐºÐµÑ‚ÑŠÑ‚ Ðµ: 'harmful'; Ð°ÐºÐ¾ ÑÑŠÐ´ÑŠÑ€Ð¶Ð°Ð½Ð¸ÐµÑ‚Ð¾ Ð½Ðµ Ðµ Ð²Ñ€ÐµÐ´Ð½Ð¾, ÐµÑ‚Ð¸ÐºÐµÑ‚ÑŠÑ‚ Ðµ: 'not'. Ð˜Ð·Ð²ÐµÐ´ÐµÑ‚Ðµ ÑÐ°Ð¼Ð¾ ÐµÐ´Ð¸Ð½ Ð½Ð¸Ð·, ÑÐ»ÐµÐ´Ð²Ð°Ð¹ÐºÐ¸ ÑˆÐ°Ð±Ð»Ð¾Ð½Ð°.\n\nÐŸÑ€Ð¸Ð¼ÐµÑ€ Ð·Ð° Ð¸Ð·Ñ…Ð¾Ð´:\nFinal Answer ==> [harmful or not]\n\n### Ð’Ñ…Ð¾Ð´: {}\n### ÐžÑ‚Ð³Ð¾Ð²Ð¾Ñ€:",
        "codebook": "### Ð˜Ð½ÑÑ‚Ñ€ÑƒÐºÑ†Ð¸Ñ: #Ð”ÐµÑ„Ð¸Ð½Ð¸Ñ†Ð¸Ñ: Ð’Ñ€ÐµÐ´ÐµÐ½ Ñ‚ÑƒÐ¸Ñ‚ Ðµ Ð¿ÑƒÐ±Ð»Ð¸ÐºÐ°Ñ†Ð¸Ñ Ð² ÑÐ¾Ñ†Ð¸Ð°Ð»Ð½Ð°Ñ‚Ð° Ð¼Ñ€ÐµÐ¶Ð° Twitter, ÐºÐ¾ÑÑ‚Ð¾ Ð¼Ð¾Ð¶Ðµ Ð´Ð° Ð¿Ñ€Ð¸Ñ‡Ð¸Ð½Ð¸ ÑÑ‚Ñ€Ð°Ð´Ð°Ð½Ð¸Ðµ, Ð²Ñ€ÐµÐ´Ð° Ð¸Ð»Ð¸ Ñ‰ÐµÑ‚Ð¸ Ð½Ð° Ð¸Ð½Ð´Ð¸Ð²Ð¸Ð´Ð¸, Ð³Ñ€ÑƒÐ¿Ð¸ Ð¸Ð»Ð¸ Ð¾Ð±Ñ‰ÐµÑÑ‚Ð²Ð¾Ñ‚Ð¾. Ð¢Ð¾Ð·Ð¸ Ñ‚Ð¸Ð¿ Ñ‚ÑƒÐ¸Ñ‚ Ð¼Ð¾Ð¶Ðµ Ð´Ð° Ð²ÐºÐ»ÑŽÑ‡Ð²Ð° ÑÑŠÐ´ÑŠÑ€Ð¶Ð°Ð½Ð¸Ðµ, ÐºÐ¾ÐµÑ‚Ð¾ Ðµ Ð¾Ð±Ð¸Ð´Ð½Ð¾, ÐºÐ»ÐµÐ²ÐµÑ‚Ð½Ð¸Ñ‡ÐµÑÐºÐ¾, Ð·Ð°Ð¿Ð»Ð°ÑˆÐ¸Ñ‚ÐµÐ»Ð½Ð¾ Ð¸Ð»Ð¸ Ð¿Ð¾Ð´Ð±ÑƒÐ¶Ð´Ð° ÐºÑŠÐ¼ Ð½Ð°ÑÐ¸Ð»Ð¸Ðµ ÑÑ€ÐµÑ‰Ñƒ Ð¿Ð¾Ð»Ð¸Ñ‚Ð¸ÐºÐ¸Ñ‚Ðµ Ð·Ð° Ð¾Ð³Ñ€Ð°Ð½Ð¸Ñ‡Ð°Ð²Ð°Ð½Ðµ Ð½Ð° Ñ€Ð°Ð·Ð¿Ñ€Ð¾ÑÑ‚Ñ€Ð°Ð½ÐµÐ½Ð¸ÐµÑ‚Ð¾ Ð½Ð° COVID-19. ÐžÑÐ²ÐµÐ½ Ñ‚Ð¾Ð²Ð°, Ð¼Ð¾Ð¶Ðµ Ð´Ð° Ñ€Ð°Ð·Ð¿Ñ€Ð¾ÑÑ‚Ñ€Ð°Ð½ÑÐ²Ð° Ñ„Ð°Ð»ÑˆÐ¸Ð²Ð° Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ, Ð´Ð° Ð´Ð¾Ð¿Ñ€Ð¸Ð½Ð°ÑÑ Ð·Ð° ÐºÐ¸Ð±ÐµÑ€Ñ‚Ð¾Ñ€Ð¼Ð¾Ð· Ð¸Ð»Ð¸ Ð´Ð° Ð¿Ð¾Ð´Ð´ÑŠÑ€Ð¶Ð° Ñ€ÐµÑ‡ Ð½Ð° Ð¾Ð¼Ñ€Ð°Ð·Ð° Ð¸ Ð´Ð¸ÑÐºÑ€Ð¸Ð¼Ð¸Ð½Ð°Ñ†Ð¸Ñ. Ð’Ñ€ÐµÐ´Ð½Ð¸Ñ‚Ðµ Ñ‚ÑƒÐ¸Ñ‚Ð¾Ð²Ðµ Ð¼Ð¾Ð³Ð°Ñ‚ Ð´Ð° Ð¸Ð¼Ð°Ñ‚ Ð¾Ñ‚Ñ€Ð¸Ñ†Ð°Ñ‚ÐµÐ»Ð½Ð¾ Ð²ÑŠÐ·Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ðµ Ð²ÑŠÑ€Ñ…Ñƒ Ð¿ÑÐ¸Ñ…Ð¸Ñ‡Ð½Ð¾Ñ‚Ð¾ Ð·Ð´Ñ€Ð°Ð²Ðµ, Ñ€ÐµÐ¿ÑƒÑ‚Ð°Ñ†Ð¸Ð¸Ñ‚Ðµ Ð¸ Ð¾Ð±Ñ‰ÐµÑÑ‚Ð²ÐµÐ½Ð°Ñ‚Ð° Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾ÑÑ‚. #Ð—Ð°Ð´Ð°Ñ‡Ð°: ÐŸÑ€Ð¾Ñ‡ÐµÑ‚ÐµÑ‚Ðµ Ð²Ð½Ð¸Ð¼Ð°Ñ‚ÐµÐ»Ð½Ð¾ Ñ€ÑŠÐºÐ¾Ð²Ð¾Ð´ÑÑ‚Ð²Ð¾Ñ‚Ð¾ Ð¸ Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»ÐµÑ‚Ðµ Ð´Ð°Ð»Ð¸ Ñ‚ÑƒÐ¸Ñ‚ÑŠÑ‚ Ðµ Ð²Ñ€ÐµÐ´ÐµÐ½ Ð·Ð° Ð¾Ð±Ñ‰ÐµÑÑ‚Ð²Ð¾Ñ‚Ð¾ Ð¸Ð»Ð¸ Ð½Ðµ. Ð˜Ð·Ð±ÐµÑ€ÐµÑ‚Ðµ ÐµÐ´Ð¸Ð½ ÐµÑ‚Ð¸ÐºÐµÑ‚: Ð°ÐºÐ¾ ÑÑŠÐ´ÑŠÑ€Ð¶Ð°Ð½Ð¸ÐµÑ‚Ð¾ Ðµ Ð²Ñ€ÐµÐ´Ð½Ð¾, ÐµÑ‚Ð¸ÐºÐµÑ‚ÑŠÑ‚ Ðµ 'harmful'; Ð°ÐºÐ¾ ÑÑŠÐ´ÑŠÑ€Ð¶Ð°Ð½Ð¸ÐµÑ‚Ð¾ Ð½Ðµ Ðµ Ð²Ñ€ÐµÐ´Ð½Ð¾, ÐµÑ‚Ð¸ÐºÐµÑ‚ÑŠÑ‚ Ðµ 'not'. Ð˜Ð·Ð²ÐµÐ´ÐµÑ‚Ðµ ÑÐ°Ð¼Ð¾ ÐµÐ´Ð¸Ð½ Ð½Ð¸Ð·, ÑÐ»ÐµÐ´Ð²Ð°Ð¹ÐºÐ¸ ÑˆÐ°Ð±Ð»Ð¾Ð½Ð°.\n\nÐŸÑ€Ð¸Ð¼ÐµÑ€ Ð·Ð° Ð¸Ð·Ñ…Ð¾Ð´:\nFinal Answer ==> [harmful or not]\n\n### Ð’Ñ…Ð¾Ð´: {}\n### ÐžÑ‚Ð³Ð¾Ð²Ð¾Ñ€:",
        "cot": "### Ð˜Ð½ÑÑ‚Ñ€ÑƒÐºÑ†Ð¸Ñ: ÐžÑ‚ÐºÑ€Ð¸Ð¹Ñ‚Ðµ Ð´Ð°Ð»Ð¸ Ñ‚ÑƒÐ¸Ñ‚ÑŠÑ‚ Ðµ Ð²Ñ€ÐµÐ´ÐµÐ½ Ð·Ð° Ð¾Ð±Ñ‰ÐµÑÑ‚Ð²Ð¾Ñ‚Ð¾ Ð¸Ð»Ð¸ Ð½Ðµ. Ð˜Ð·Ð±ÐµÑ€ÐµÑ‚Ðµ ÐµÐ´Ð¸Ð½ ÐµÑ‚Ð¸ÐºÐµÑ‚: Ð°ÐºÐ¾ ÑÑŠÐ´ÑŠÑ€Ð¶Ð°Ð½Ð¸ÐµÑ‚Ð¾ Ðµ Ð²Ñ€ÐµÐ´Ð½Ð¾, ÐµÑ‚Ð¸ÐºÐµÑ‚ÑŠÑ‚ Ðµ: 'harmful'; Ð°ÐºÐ¾ ÑÑŠÐ´ÑŠÑ€Ð¶Ð°Ð½Ð¸ÐµÑ‚Ð¾ Ð½Ðµ Ðµ Ð²Ñ€ÐµÐ´Ð½Ð¾, ÐµÑ‚Ð¸ÐºÐµÑ‚ÑŠÑ‚ Ðµ: 'not'. Ð˜Ð·Ð²ÐµÐ´ÐµÑ‚Ðµ ÑÐ°Ð¼Ð¾ ÐµÐ´Ð¸Ð½ Ð½Ð¸Ð·, ÑÐ»ÐµÐ´Ð²Ð°Ð¹ÐºÐ¸ ÑˆÐ°Ð±Ð»Ð¾Ð½Ð°.\n\nÐŸÑ€Ð¸Ð¼ÐµÑ€ Ð·Ð° Ð¸Ð·Ñ…Ð¾Ð´:\nFinal Answer ==> [harmful or not]. ÐžÐ±Ð¾ÑÐ½Ð¾Ð²ÐºÐ° ÑÑ‚ÑŠÐ¿ÐºÐ° Ð¿Ð¾ ÑÑ‚ÑŠÐ¿ÐºÐ°: 1. **Ð›ÐµÐºÑÐ¸ÐºÐ°Ð»ÐµÐ½ Ð°Ð½Ð°Ð»Ð¸Ð·**: Ð˜Ð´ÐµÐ½Ñ‚Ð¸Ñ„Ð¸Ñ†Ð¸Ñ€Ð°Ð¹Ñ‚Ðµ ÐºÐ»ÑŽÑ‡Ð¾Ð²Ð¸ Ð´ÑƒÐ¼Ð¸ Ð¸ Ñ„Ñ€Ð°Ð·Ð¸, ÐºÐ¾Ð¸Ñ‚Ð¾ Ð¼Ð¾Ð³Ð°Ñ‚ Ð´Ð° ÑÑŠÐ´ÑŠÑ€Ð¶Ð°Ñ‚ Ð²Ñ€ÐµÐ´Ð½Ð° Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ Ð¸ Ð½Ð°Ð¼ÐµÑ€ÐµÐ½Ð¸Ñ. 2. **ÐÐ½Ð°Ð»Ð¸Ð· Ð½Ð° Ð½Ð°ÑÑ‚Ñ€Ð¾ÐµÐ½Ð¸ÐµÑ‚Ð¾**: ÐÐ½Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð°Ð¹Ñ‚Ðµ Ñ‚Ð¾Ð½Ð° Ð¸ ÐµÐ·Ð¸ÐºÐ°, Ð·Ð° Ð´Ð° Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»Ð¸Ñ‚Ðµ Ð´Ð°Ð»Ð¸ Ð¸Ð¼Ð° Ð½ÐµÐ²Ð¾Ð»Ð½Ð¾ Ð¸Ð»Ð¸ ÑƒÐ¼Ð¸ÑˆÐ»ÐµÐ½Ð¾ Ð²Ñ€ÐµÐ´Ð½Ð¾ Ð¿Ð¾Ð²ÐµÐ´ÐµÐ½Ð¸Ðµ, Ð´ÑƒÐ¼Ð¸ Ð¸Ð»Ð¸ ÐµÐ¼Ð¾Ñ†Ð¸Ð¾Ð½Ð°Ð»ÐµÐ½ ÐµÐ·Ð¸Ðº. 3. **ÐÑƒÐ´Ð¸Ñ‚Ð¾Ñ€Ð¸Ñ**: Ð˜Ð´ÐµÐ½Ñ‚Ð¸Ñ„Ð¸Ñ†Ð¸Ñ€Ð°Ð¹Ñ‚Ðµ Ñ†ÐµÐ»ÐµÐ²Ð°Ñ‚Ð° Ð°ÑƒÐ´Ð¸Ñ‚Ð¾Ñ€Ð¸Ñ: ÐšÐ¾Ñ Ð¸Ð·Ð³Ð»ÐµÐ¶Ð´Ð° Ð´Ð° Ðµ Ñ†ÐµÐ»ÐµÐ²Ð°Ñ‚Ð° Ð°ÑƒÐ´Ð¸Ñ‚Ð¾Ñ€Ð¸Ñ Ð·Ð° Ñ‚Ð¾Ð·Ð¸ Ñ‚ÑƒÐ¸Ñ‚? 4. **Ð—Ð°Ð¿Ð»Ð°Ñ…Ð¸ Ð¸ Ñ‚Ð¾Ñ€Ð¼Ð¾Ð·**: ÐŸÑ€ÐµÐºÐ¸ Ð¸Ð»Ð¸ Ð·Ð°Ð²Ð¾Ð°Ð»Ð¸Ñ€Ð°Ð½Ð¸ Ð·Ð°Ð¿Ð»Ð°Ñ…Ð¸ Ð·Ð° Ð½Ð°ÑÐ¸Ð»Ð¸Ðµ, Ñ„Ð¸Ð·Ð¸Ñ‡ÐµÑÐºÐ° Ð²Ñ€ÐµÐ´Ð° Ð¸Ð»Ð¸ Ñ‚Ð¾Ñ€Ð¼Ð¾Ð·. Ð¢Ð¾Ð²Ð° Ð²ÐºÐ»ÑŽÑ‡Ð²Ð° Ñ€Ð°Ð·ÐºÑ€Ð¸Ð²Ð°Ð½Ðµ Ð½Ð° Ð»Ð¸Ñ‡Ð½Ð° Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ (doxing), Ð¿Ñ€ÐµÑÐ»ÐµÐ´Ð²Ð°Ð½Ðµ Ð¸Ð»Ð¸ Ð¿Ð¾Ð´Ð±ÑƒÐ¶Ð´Ð°Ð½Ðµ Ð½Ð° Ð´Ñ€ÑƒÐ³Ð¸ ÐºÑŠÐ¼ Ñ‚Ð¾Ñ€Ð¼Ð¾Ð·. 5. **Ð’Ñ€Ð°Ð¶Ð´ÐµÐ±Ð½Ð° Ñ€ÐµÑ‡**: Ð˜Ð·Ñ€Ð°Ð·Ð¸ Ð½Ð° Ð¾Ð¼Ñ€Ð°Ð·Ð°, Ð½ÐµÑ‚ÑŠÑ€Ð¿Ð¸Ð¼Ð¾ÑÑ‚ Ð¸Ð»Ð¸ Ð¿Ñ€ÐµÐ´Ñ€Ð°Ð·ÑÑŠÐ´ÑŠÑ†Ð¸ ÑÑ€ÐµÑ‰Ñƒ ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ð¸ Ð³Ñ€ÑƒÐ¿Ð¸. Ð¢Ð¾Ð²Ð° Ð¼Ð¾Ð¶Ðµ Ð´Ð° ÑÐµ Ð¿Ñ€Ð¾ÑÐ²Ð¸ ÐºÐ°Ñ‚Ð¾ Ð´ÐµÑ…ÑƒÐ¼Ð°Ð½Ð¸Ð·Ð¸Ñ€Ð°Ñ‰ ÐµÐ·Ð¸Ðº, Ð¿Ñ€Ð¸Ð·Ð¸Ð²Ð¸ Ð·Ð° Ð½Ð°ÑÐ¸Ð»Ð¸Ðµ Ð¸Ð»Ð¸ Ð½Ð°ÑÑŠÑ€Ñ‡Ð°Ð²Ð°Ð½Ðµ Ð½Ð° Ð´Ð¸ÑÐºÑ€Ð¸Ð¼Ð¸Ð½Ð°Ñ†Ð¸Ð¾Ð½Ð½Ð¸ Ð¸Ð´ÐµÐ¾Ð»Ð¾Ð³Ð¸Ð¸. 6. **Ð”ÐµÐ·Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ Ð¸ Ñ„Ð°Ð»ÑˆÐ¸Ð²Ð° Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ**: Ð Ð°Ð·Ð¿Ñ€Ð¾ÑÑ‚Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ Ð½Ð° Ñ„Ð°Ð»ÑˆÐ¸Ð²Ð° Ð¸Ð»Ð¸ Ð¿Ð¾Ð´Ð²ÐµÐ¶Ð´Ð°Ñ‰Ð° Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ, Ñ‡ÐµÑÑ‚Ð¾ Ñ Ð½Ð°Ð¼ÐµÑ€ÐµÐ½Ð¸Ðµ Ð´Ð° Ð·Ð°Ð±Ð»ÑƒÐ´Ð¸ Ð¸Ð»Ð¸ Ð¼Ð°Ð½Ð¸Ð¿ÑƒÐ»Ð¸Ñ€Ð°. Ð¢Ð¾Ð²Ð° Ð¼Ð¾Ð¶Ðµ Ð´Ð° Ð²ÐºÐ»ÑŽÑ‡Ð²Ð° ÐºÐ¾Ð½ÑÐ¿Ð¸Ñ€Ð°Ñ‚Ð¸Ð²Ð½Ð¸ Ñ‚ÐµÐ¾Ñ€Ð¸Ð¸, Ñ„Ð°Ð»ÑˆÐ¸Ð²Ð¸ Ð½Ð¾Ð²Ð¸Ð½Ð¸ Ð¸Ð»Ð¸ Ð¼Ð°Ð½Ð¸Ð¿ÑƒÐ»Ð¸Ñ€Ð°Ð½Ð¸ Ð¼ÐµÐ´Ð¸Ð¸. 7. **ÐšÐ¸Ð±ÐµÑ€Ñ‚Ð¾Ñ€Ð¼Ð¾Ð·**: ÐÐ³Ñ€ÐµÑÐ¸Ð²Ð½Ð¾ Ð¸Ð»Ð¸ ÑƒÐ¼Ð¸ÑˆÐ»ÐµÐ½Ð¾ Ð¿Ð¾Ð²ÐµÐ´ÐµÐ½Ð¸Ðµ Ñ‡Ñ€ÐµÐ· ÐµÐ»ÐµÐºÑ‚Ñ€Ð¾Ð½Ð½Ð¸ ÐºÐ¾Ð¼ÑƒÐ½Ð¸ÐºÐ°Ñ†Ð¸Ð¸ Ñ Ñ†ÐµÐ» Ð´Ð° Ð½Ð°Ð²Ñ€ÐµÐ´Ð¸, ÑƒÐ½Ð¸Ð¶Ð¸ Ð¸Ð»Ð¸ Ð·Ð°Ð¿Ð»Ð°ÑˆÐ¸ Ð¸Ð½Ð´Ð¸Ð²Ð¸Ð´. ÐšÑ€Ð°Ñ‚ÐºÐ¾ Ð¾Ð±ÑÑÐ½ÐµÐ½Ð¸Ðµ Ð·Ð° Ð²ÑÑÐºÐ° ÑÑ‚ÑŠÐ¿ÐºÐ°: [ÐžÐ±ÑÑÐ½ÐµÐ½Ð¸Ðµ]. Final Answer ==> [harmful or not]\n\n### Ð’Ñ…Ð¾Ð´: {}\n### ÐžÑ‚Ð³Ð¾Ð²Ð¾Ñ€:"
    },
    "clef_1c_ar": {
        "zero_shot_generic": "### Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª: Ø­Ø¯Ù‘Ø¯ Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„ØªØºØ±ÙŠØ¯Ø© Ø¶Ø§Ø±Ø© Ø¨Ø§Ù„Ù…Ø¬ØªÙ…Ø¹ Ø£Ù… Ù„Ø§. Ø§Ø®ØªØ± ØªØµÙ†ÙŠÙÙ‹Ø§ ÙˆØ§Ø­Ø¯Ù‹Ø§: Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø¶Ø§Ø±Ù‹Ø§ØŒ ÙØ¥Ù† Ø§Ù„ØªØµÙ†ÙŠÙ Ù‡Ùˆ: 'harmful'Ø› ÙˆØ¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ø¶Ø§Ø±Ù‹Ø§ØŒ ÙØ¥Ù† Ø§Ù„ØªØµÙ†ÙŠÙ Ù‡Ùˆ: 'not'. Ø£Ø®Ø±Ø¬ Ø³Ù„Ø³Ù„Ø© ÙˆØ§Ø­Ø¯Ø© ÙÙ‚Ø· ÙˆÙÙ‚Ù‹Ø§ Ù„Ù„Ù‚Ø§Ù„Ø¨.\n\nÙ…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª:\nFinal Answer ==> [harmful or not]\n\n### Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„: {}\n### Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©:",
        "zero_shot_specific": "### Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª: Ø§Ù„ØªØºØ±ÙŠØ¯Ø© Ø§Ù„Ø¶Ø§Ø±Ø© Ù‡ÙŠ Ù…Ù†Ø´ÙˆØ± Ø¹Ù„Ù‰ Ù…Ù†ØµØ© Ø§Ù„ØªÙˆØ§ØµÙ„ Ø§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠ ØªÙˆÙŠØªØ± ÙŠÙ…ÙƒÙ† Ø£Ù† ÙŠØªØ³Ø¨Ø¨ ÙÙŠ Ø§Ù„Ø£Ø°Ù‰ Ø£Ùˆ Ø§Ù„Ø¶Ø±Ø± Ø£Ùˆ Ø§Ù„Ø¥Ø²Ø¹Ø§Ø¬ Ù„Ù„Ø£ÙØ±Ø§Ø¯ Ø£Ùˆ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø£Ùˆ Ø§Ù„Ù…Ø¬ØªÙ…Ø¹. Ù‚Ø¯ ØªØªØ¶Ù…Ù† Ù‡Ø°Ù‡ Ø§Ù„ØªØºØ±ÙŠØ¯Ø© Ù…Ø­ØªÙˆÙ‰ Ù…Ø³ÙŠØ¦Ù‹Ø§ Ø£Ùˆ ØªØ­Ø±ÙŠØ¶ÙŠÙ‹Ø§ Ø£Ùˆ ÙƒØ§Ø°Ø¨Ù‹Ø§ Ø£Ùˆ ØªÙ‡Ø¯ÙŠØ¯ÙŠÙ‹Ø§ Ø£Ùˆ ÙŠØ´Ø¬Ø¹ Ø¹Ù„Ù‰ Ø§Ù„Ø¹Ù†Ù Ø£Ùˆ ÙŠÙ†Ø´Ø± Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…Ø¶Ù„Ù„Ø© Ø£Ùˆ ÙŠØ±ÙˆØ¬ Ù„Ø®Ø·Ø§Ø¨ Ø§Ù„ÙƒØ±Ø§Ù‡ÙŠØ© Ø£Ùˆ Ø§Ù„ØªÙ…ÙŠÙŠØ². Ø§Ù„ØªØºØ±ÙŠØ¯Ø§Øª Ø§Ù„Ø¶Ø§Ø±Ø© ÙŠÙ…ÙƒÙ† Ø£Ù† ØªØ¤Ø«Ø± Ø³Ù„Ø¨Ù‹Ø§ Ø¹Ù„Ù‰ Ø§Ù„ØµØ­Ø© Ø§Ù„Ù†ÙØ³ÙŠØ© ÙˆØ§Ù„Ø³Ù„Ø§Ù…Ø© Ø§Ù„Ø¹Ø§Ù…Ø© ÙˆØ§Ù„Ø³Ù…Ø¹Ø©. Ø­Ø¯Ù‘Ø¯ Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„ØªØºØ±ÙŠØ¯Ø© Ø¶Ø§Ø±Ø© Ø¨Ø§Ù„Ù…Ø¬ØªÙ…Ø¹ Ø£Ù… Ù„Ø§. Ø§Ø®ØªØ± ØªØµÙ†ÙŠÙÙ‹Ø§ ÙˆØ§Ø­Ø¯Ù‹Ø§: Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø¶Ø§Ø±Ù‹Ø§ØŒ ÙØ¥Ù† Ø§Ù„ØªØµÙ†ÙŠÙ Ù‡Ùˆ: 'harmful'Ø› ÙˆØ¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ø¶Ø§Ø±Ù‹Ø§ØŒ ÙØ¥Ù† Ø§Ù„ØªØµÙ†ÙŠÙ Ù‡Ùˆ: 'not'. Ø£Ø®Ø±Ø¬ Ø³Ù„Ø³Ù„Ø© ÙˆØ§Ø­Ø¯Ø© ÙÙ‚Ø· ÙˆÙÙ‚Ù‹Ø§ Ù„Ù„Ù‚Ø§Ù„Ø¨.\n\nÙ…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª:\nFinal Answer ==> [harmful or not]\n\n### Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„: {}\n### Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©:",
        "few_shot": "### Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª: Ø­Ø¯Ù‘Ø¯ Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„ØªØºØ±ÙŠØ¯Ø© Ø¶Ø§Ø±Ø© Ø¨Ø§Ù„Ù…Ø¬ØªÙ…Ø¹ Ø£Ù… Ù„Ø§. Ø§Ø®ØªØ± ØªØµÙ†ÙŠÙÙ‹Ø§ ÙˆØ§Ø­Ø¯Ù‹Ø§: Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø¶Ø§Ø±Ù‹Ø§ØŒ ÙØ¥Ù† Ø§Ù„ØªØµÙ†ÙŠÙ Ù‡Ùˆ: 'harmful'Ø› ÙˆØ¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ø¶Ø§Ø±Ù‹Ø§ØŒ ÙØ¥Ù† Ø§Ù„ØªØµÙ†ÙŠÙ Ù‡Ùˆ: 'not'. Ø£Ø®Ø±Ø¬ Ø³Ù„Ø³Ù„Ø© ÙˆØ§Ø­Ø¯Ø© ÙÙ‚Ø· ÙˆÙÙ‚Ù‹Ø§ Ù„Ù„Ù‚Ø§Ù„Ø¨.\n\nÙ…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª:\nFinal Answer ==> [harmful or not]\n\n### Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„: {}\n### Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©:",
        "codebook": "### Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª: #Ø§Ù„ØªØ¹Ø±ÙŠÙ: Ø§Ù„ØªØºØ±ÙŠØ¯Ø© Ø§Ù„Ø¶Ø§Ø±Ø© Ù‡ÙŠ Ù…Ù†Ø´ÙˆØ± Ø¹Ù„Ù‰ ØªÙˆÙŠØªØ± ÙŠÙ…ÙƒÙ† Ø£Ù† ÙŠØ³Ø¨Ø¨ Ø¶Ø±Ø±Ù‹Ø§ Ø£Ùˆ Ø¥Ø²Ø¹Ø§Ø¬Ù‹Ø§ Ù„Ù„Ø£ÙØ±Ø§Ø¯ Ø£Ùˆ Ø§Ù„Ù…Ø¬ØªÙ…Ø¹. Ù‚Ø¯ ØªØ´Ù…Ù„ Ø§Ù„ØªØºØ±ÙŠØ¯Ø© Ø§Ù„Ø¶Ø§Ø±Ø© Ù…Ø­ØªÙˆÙ‰ Ù…Ø¶Ù„Ù„Ù‹Ø§ØŒ Ù†Ø¸Ø±ÙŠØ§Øª Ù…Ø¤Ø§Ù…Ø±Ø©ØŒ Ø£Ùˆ Ø§Ø¯Ø¹Ø§Ø¡Ø§Øª Ø·Ø¨ÙŠØ© ØºÙŠØ± ØµØ­ÙŠØ­Ø©. #Ø§Ù„Ù…Ù‡Ù…Ø©: Ø§Ù‚Ø±Ø£ Ø§Ù„Ø¯Ù„ÙŠÙ„ Ø¨Ø¹Ù†Ø§ÙŠØ© ÙˆØ­Ø¯Ù‘Ø¯ Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„ØªØºØ±ÙŠØ¯Ø© Ø¶Ø§Ø±Ø© Ø¨Ø§Ù„Ù…Ø¬ØªÙ…Ø¹ Ø£Ù… Ù„Ø§. Ø§Ø®ØªØ± ØªØµÙ†ÙŠÙÙ‹Ø§ ÙˆØ§Ø­Ø¯Ù‹Ø§: Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø¶Ø§Ø±Ù‹Ø§ØŒ ÙØ¥Ù† Ø§Ù„ØªØµÙ†ÙŠÙ Ù‡Ùˆ 'harmful'Ø› ÙˆØ¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ø¶Ø§Ø±Ù‹Ø§ØŒ ÙØ¥Ù† Ø§Ù„ØªØµÙ†ÙŠÙ Ù‡Ùˆ 'not'. Ø£Ø®Ø±Ø¬ Ø³Ù„Ø³Ù„Ø© ÙˆØ§Ø­Ø¯Ø© ÙÙ‚Ø· ÙˆÙÙ‚Ù‹Ø§ Ù„Ù„Ù‚Ø§Ù„Ø¨.\n\nÙ…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª:\nFinal Answer ==> [harmful or not]\n\n### Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„: {}\n### Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©:",
        "cot": "### Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª: Ø­Ø¯Ù‘Ø¯ Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„ØªØºØ±ÙŠØ¯Ø© Ø¶Ø§Ø±Ø© Ø¨Ø§Ù„Ù…Ø¬ØªÙ…Ø¹ Ø£Ù… Ù„Ø§. Ø§Ø®ØªØ± ØªØµÙ†ÙŠÙÙ‹Ø§ ÙˆØ§Ø­Ø¯Ù‹Ø§: Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø¶Ø§Ø±Ù‹Ø§ØŒ ÙØ¥Ù† Ø§Ù„ØªØµÙ†ÙŠÙ Ù‡Ùˆ: 'harmful'Ø› ÙˆØ¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ø¶Ø§Ø±Ù‹Ø§ØŒ ÙØ¥Ù† Ø§Ù„ØªØµÙ†ÙŠÙ Ù‡Ùˆ: 'not'. Ø£Ø®Ø±Ø¬ Ø³Ù„Ø³Ù„Ø© ÙˆØ§Ø­Ø¯Ø© ÙÙ‚Ø· ÙˆÙÙ‚Ù‹Ø§ Ù„Ù„Ù‚Ø§Ù„Ø¨.\n\nÙ…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª:\nFinal Answer ==> [harmful or not].\n\nØ®Ø·ÙˆØ§Øª Ø§Ù„ØªØ­Ù„ÙŠÙ„:\n1. **Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù„ØºÙˆÙŠ**: ØªØ­Ø¯ÙŠØ¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø£Ùˆ Ø§Ù„Ø¹Ø¨Ø§Ø±Ø§Øª Ø§Ù„ØªÙŠ Ù‚Ø¯ ØªØ´ÙŠØ± Ø¥Ù„Ù‰ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¶Ø§Ø±Ø© Ø£Ùˆ Ù†ÙŠØ© Ø³ÙŠØ¦Ø©.\n2. **ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±**: ÙØ­Øµ Ù†Ø¨Ø±Ø© Ø§Ù„ØªØºØ±ÙŠØ¯Ø© Ù„ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø§Ø·ÙÙŠØ© Ø£Ùˆ Ø§Ù„Ø¹Ø¯ÙˆØ§Ù†ÙŠØ©.\n3. **ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¬Ù…Ù‡ÙˆØ±**: Ù…Ù† Ù‡Ùˆ Ø§Ù„Ø¬Ù…Ù‡ÙˆØ± Ø§Ù„Ù…Ø³ØªÙ‡Ø¯ÙØŸ\n4. **Ø§Ù„ØªÙ‡Ø¯ÙŠØ¯Ø§Øª ÙˆØ§Ù„ØªØ­Ø±Ø´**: Ø§Ù„ÙƒØ´Ù Ø¹Ù† Ø£ÙŠ ØªÙ‡Ø¯ÙŠØ¯Ø§Øª Ù…Ø¨Ø§Ø´Ø±Ø© Ø£Ùˆ ØºÙŠØ± Ù…Ø¨Ø§Ø´Ø±Ø© Ø£Ùˆ ØªØ­Ø±Ø´.\n5. **Ø§Ù„Ø®Ø·Ø§Ø¨ Ø§Ù„Ø¹Ø¯Ø§Ø¦ÙŠ**: ØªØ­Ø¯ÙŠØ¯ Ù„ØºØ© Ø§Ù„ÙƒØ±Ø§Ù‡ÙŠØ© Ø£Ùˆ Ø§Ù„Ø¯Ø¹ÙˆØ© Ø¥Ù„Ù‰ Ø§Ù„Ø¹Ù†Ù Ø£Ùˆ Ø§Ù„ØªÙ…ÙŠÙŠØ².\n6. **Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ø¶Ù„Ù„Ø©**: Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø®Ø§Ø·Ø¦Ø© Ø£Ùˆ Ù†Ø¸Ø±ÙŠØ§Øª Ù…Ø¤Ø§Ù…Ø±Ø© Ø£Ùˆ Ø£Ø®Ø¨Ø§Ø± ÙƒØ§Ø°Ø¨Ø©.\n7. **Ø§Ù„Ø§Ø³ØªÙ†ØªØ§Ø¬**: Ø´Ø±Ø­ Ù…Ø®ØªØµØ± Ù„ÙƒÙ„ Ø®Ø·ÙˆØ©.\n\nFinal Answer ==> [harmful or not]\n\n### Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„: {}\n### Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©:"
    }
}